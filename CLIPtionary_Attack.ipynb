{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLIPtionary Attack",
      "provenance": [],
      "collapsed_sections": [
        "N4elyNboOtVr",
        "DSZVuX7YK_d_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4elyNboOtVr"
      },
      "source": [
        "# CLIPtionary Attack Notebook\n",
        "<h2>License</h2>\n",
        "Copyright (c) 2021 Bearsharktopusdev\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSZVuX7YK_d_"
      },
      "source": [
        "# HOW TO USE\n",
        "<h2>Upload your image in the file thing. Put the image path in Parameters as indicated. Fill in other parameters as desired. Restart + Run All and then go get some coffee because it'll take a little bit.</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqAJx0uQK7Fk"
      },
      "source": [
        "# Imports & Shit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "VsFJu8yZtdBW",
        "outputId": "30f4b13b-41e1-44e0-a118-0cd5a94e54ff"
      },
      "source": [
        "#@markdown\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 29 19:12:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUulcXSt5sgp"
      },
      "source": [
        "#@markdown\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "\n",
        "%cd /content/CLIP/\n",
        "\n",
        "!pip install ftfy\n",
        "!pip install tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "import imageio\n",
        "import torchvision\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "import clip\n",
        "!pip install kornia\n",
        "import kornia\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import random\n",
        "\n",
        "clip.available_models()\n",
        "\n",
        "#RN50x4\n",
        "#ViT-B/32\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "perceptor, preprocess = clip.load('ViT-B/32', jit=True) # usually use vit\n",
        "perceptor = perceptor.eval()\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAyVxk1A62nR"
      },
      "source": [
        "#@markdown\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/first20hours/google-10000-english\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KusQPKY7oXC"
      },
      "source": [
        "#@markdown\n",
        "file = open(\"/content/google-10000-english/google-10000-english-usa-no-swears-short.txt\", \"r\")\n",
        "short_list = file.read().splitlines()\n",
        "file.close()\n",
        "\n",
        "file = open(\"/content/google-10000-english/google-10000-english-usa-no-swears-medium.txt\", \"r\")\n",
        "medium_list = file.read().splitlines()\n",
        "file.close()\n",
        "\n",
        "file = open(\"/content/google-10000-english/google-10000-english-usa-no-swears-long.txt\", \"r\")\n",
        "long_list = file.read().splitlines()\n",
        "file.close()\n",
        "\n",
        "file = open(\"/content/google-10000-english/20k.txt\", \"r\")\n",
        "full_list = file.read().splitlines()\n",
        "file.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_--w7FGKft9"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfFXuj4oDAuh"
      },
      "source": [
        "check_amount = 200 #100, number of terms to contest per epoch\n",
        "seed_epochs = 4000 #10, number of iterations of the checking algorithm for the initial seeding\n",
        "self_comp_epochs = 5 #4, number of iterations of the self-comparative attack\n",
        "culling_threshold = 1.0 #1.2, any phrase worth less than this many words is culled from the list. \n",
        "# for example, with a threshold of 1 and 100 words, any word that scores less than 0.01 (1/100) is culled\n",
        "# Recommended to be kept between 1 and 2\n",
        "\n",
        "seed_words = \"sentinel, statue\" #\"\", comma separated list of words to seed the initial epochs with.\n",
        "image = \"/content/vacation.jpg\" #don't delete /content/, just upload to google colab and put your filename there\n",
        "\n",
        "dictionary_from_top = 20 #Adds this many words from the top of the frequency-rated dictionary to the dictionary attack\n",
        "dictionary_from_random = 20 #Adds this many words randomly from the frequency-rated dictionary to the dictionary attack\n",
        "\n",
        "iterative_guess_words = \"\" #\"\", comma separated list of words for the iterative guess & check step\n",
        "\n",
        "\n",
        "heavy_dictionary = True #False, when true, runs through a text file of ~500,000 english words with no frequency rating as opposed to the 20,000 word corpus used.\n",
        "second_run = True #False, when true, runs the initial dictionary seeding a second time just to check for stragglers.\n",
        "progress_bar_seed = False #False, enables progress bar on the seeding round rather than seeing live results."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yp2bzFKIlF2c"
      },
      "source": [
        "#@markdown\n",
        "\n",
        "if heavy_dictionary:\n",
        "  !git clone https://github.com/dwyl/english-words\n",
        "  file = open(\"/content/english-words/words.txt\", \"r\")\n",
        "  heavy_list = file.read().splitlines()\n",
        "  file.close()\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq4dg88eKi3G"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE8U-glQ6NRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e673de1-05b3-480b-cacd-52aa31f66b17"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
        "\n",
        "image = preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
        "image_features = model.encode_image(image)\n",
        "\n",
        "winner_list = []\n",
        "\n",
        "def rate_words(input_list):\n",
        "  text = clip.tokenize(input_list).to(device)\n",
        "\n",
        "  for i in input_list:\n",
        "    \" \".join(i.split())\n",
        "\n",
        "  with torch.no_grad():\n",
        "      text_features = model.encode_text(text)\n",
        "      \n",
        "      logits_per_image, logits_per_text = model(image, text)\n",
        "      probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "  probs_list = probs.tolist()[0]\n",
        "  input_probs_zip = zip(input_list, probs_list)\n",
        "  input_probs_list = []\n",
        "  for i in input_probs_zip:\n",
        "    input_probs_list.append(i)\n",
        "  result = [i for i in input_probs_list if i[1] >= max(culling_threshold/len(input_list), 0.5/check_amount)]\n",
        "  result = remove_duplicates(result)\n",
        "  result.sort(key=lambda x:x[1], reverse=True)\n",
        "\n",
        "  return result\n",
        "\n",
        "list_index = check_amount\n",
        "def refill_list(input_list):\n",
        "  global list_index\n",
        "  pull_list = []\n",
        "  if heavy_dictionary:\n",
        "    pull_list = heavy_list\n",
        "  else:\n",
        "    pull_list = full_list\n",
        "  while len(input_list) < check_amount and list_index < len(pull_list):\n",
        "    input_list.append(pull_list[list_index])\n",
        "    list_index = list_index + 1\n",
        "  if list_index >= len(pull_list):\n",
        "    random_list = random.sample(pull_list, check_amount)\n",
        "    while len(input_list) < check_amount:\n",
        "      input_list.append(random_list[0])\n",
        "      random_list.pop(0)\n",
        "\n",
        "def remove_duplicates(input_list):\n",
        "    return list(set([i for i in input_list]))\n",
        "\n",
        "def attack(input_list):\n",
        "  for k in input_list:\n",
        "    global winner_list\n",
        "    winner_list = remove_duplicates(winner_list)\n",
        "    thing = [x[0] for x in winner_list]\n",
        "    thinglen = len(thing)\n",
        "    thinglenlen = len(str.split(thing[0]))+1\n",
        "    new_list = [thing]*thinglenlen\n",
        "    new_new_list = []\n",
        "    for i in range(thinglenlen):\n",
        "      for j in new_list[i]:\n",
        "        newj = str.split(j)\n",
        "        newj.insert(i, k)\n",
        "        newj = \" \".join(newj)\n",
        "        new_new_list.append(newj)\n",
        "    for i in thing:\n",
        "      new_new_list.append(i)\n",
        "    new_new_list.append(k)\n",
        "\n",
        "    winner_list = rate_words(new_new_list)\n",
        "\n",
        "    print('\\n---\\nprinting top 10')\n",
        "    winner_list.sort(key=lambda x:x[1], reverse=True)\n",
        "    for i in range(len(winner_list)):\n",
        "      if i < 10:\n",
        "        print(winner_list[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 335M/335M [00:05<00:00, 61.9MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBGyI2X3KnIH"
      },
      "source": [
        "# Dictionary Seeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3634iR76pM1"
      },
      "source": [
        "seed_word_list = seed_words.split(\", \")\n",
        "if heavy_dictionary:\n",
        "  initial_attack = heavy_list[0:check_amount - len(seed_word_list)]\n",
        "else:\n",
        "  initial_attack = full_list[0:check_amount - len(seed_word_list)]\n",
        "initial_attack = initial_attack + seed_word_list\n",
        "\n",
        "if progress_bar_seed:\n",
        "  for i in trange(seed_epochs):\n",
        "    refill_list(initial_attack)\n",
        "    winner_list = rate_words(initial_attack)\n",
        "    initial_attack = [x[0] for x in winner_list]\n",
        "\n",
        "  print('\\n---')\n",
        "  for i in winner_list:\n",
        "    print(i)\n",
        "else:\n",
        "  for i in range(seed_epochs):\n",
        "    refill_list(initial_attack)\n",
        "    winner_list = rate_words(initial_attack)\n",
        "    initial_attack = [x[0] for x in winner_list]\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    pprint(winner_list[0:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5EXW_4KtJ9s"
      },
      "source": [
        "# Self-Comparing Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mEVRyAztOp9"
      },
      "source": [
        "self_comp_attack = []\n",
        "temp = []\n",
        "\n",
        "new = [x[0] for x in winner_list]\n",
        "\n",
        "for j in range(self_comp_epochs):\n",
        "  if j == 0:\n",
        "    for k in new:\n",
        "      for i in new:\n",
        "        self_comp_attack.append(k + \" \" + i)\n",
        "      self_comp_attack.append(k)\n",
        "  else:\n",
        "    for k in new:\n",
        "      for i in temp:\n",
        "        self_comp_attack.append(k + \" \" + i)\n",
        "\n",
        "  winner_list = rate_words(self_comp_attack)\n",
        "  self_comp_attack = [x[0] for x in winner_list]\n",
        "  temp = [x[0] for x in winner_list]\n",
        "\n",
        "  print('\\n---\\nprinting top 10')\n",
        "  for i in range(len(winner_list)):\n",
        "    if i < 10:\n",
        "      print(winner_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dATx3_hOShJ"
      },
      "source": [
        "# Iterative Dictionary Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQzWCSLWmYpy"
      },
      "source": [
        "dictionary_attack = full_list[0:dictionary_from_top]\n",
        "random_list = random.sample(full_list, dictionary_from_random)\n",
        "dictionary_attack = random_list + dictionary_attack\n",
        "\n",
        "attack(dictionary_attack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnqPx5nVQRsz"
      },
      "source": [
        "# Synonym/Antonym Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Y0zz_NmZBN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwTBP7JH2vay"
      },
      "source": [
        "# Iterative Guess & Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioQ64hgd7AO3"
      },
      "source": [
        "words_list = iterative_guess_words.split(\", \")\n",
        "\n",
        "attack(words_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}